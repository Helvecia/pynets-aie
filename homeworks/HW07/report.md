# HW07 – Report

## 1. Datasets

Выбраны 3 датасета из 4:
- S07-hw-dataset-01.csv (множественные признаки разных шкал)
- S07-hw-dataset-02.csv (нелинейная структура с выбросами)
- S07-hw-dataset-03.csv (кластеры разной плотности)

### 1.1 Dataset 01 (S07-hw-dataset-01.csv)

- **Файл**: `S07-hw-dataset-01.csv`
- **Размер**: 12,000 строк × 8 признаков (+ sample_id)
- **Признаки**: 8 числовых признаков (f01–f08)
- **Пропуски**: Нет пропусков
- **"Подлости" датасета**: 
  - Признаки в разных шкалах (f02 в диапазоне [−93, 112], f07 в диапазоне [−215, 213])
  - Необходимо масштабирование (StandardScaler)
  - Наличие шумовых признаков, которые усложняют интерпретацию структуры

### 1.2 Dataset 02 (S07-hw-dataset-02.csv)

- **Файл**: `S07-hw-dataset-02.csv`
- **Размер**: 8,000 строк × 3 признаков (+ sample_id)
- **Признаки**: x1, x2, z_noise (2D структура + шум)
- **Пропуски**: Нет пропусков
- **"Подлости" датасета**:
  - Нелинейная структура кластеров (что демонстрирует ограничения KMeans)
  - Наличие выбросов в шумовом признаке z_noise
  - Требует аккуратного выбора алгоритма и параметров

### 1.3 Dataset 03 (S07-hw-dataset-03.csv)

- **Файл**: `S07-hw-dataset-03.csv`
- **Размер**: 15,000 строк × 4 признаков (+ sample_id)
- **Признаки**: x1, x2, f_corr, f_noise (признаки с различной степенью коррелированности)
- **Пропуски**: Нет пропусков
- **"Подлости" датасета**:
  - Кластеры с разной плотностью (что затрудняет DBSCAN)
  - Наличие фонового шума и выбросов
  - Высокая чувствительность к выбору параметров DBSCAN (eps, min_samples)

---

## 2. Protocol

### Препроцессинг
- **StandardScaler**: применена ко всем числовым признакам для нормализации шкал
- **Обработка пропусков**: в выбранных датасетах пропусков нет; для Dataset-04 (неиспользуемого) применялась бы SimpleImputer
- **Кодирование категориальных признаков**: не требовалось для выбранных датасетов

### Поиск гиперпараметров
- **KMeans**: подбор k в диапазоне [2, 20] с фиксированными random_state=42 и n_init=10
- **DBSCAN**: подбор eps в диапазоне [0.3, 2.0] и min_samples в {5, 10, 15}; учитываются только конфигурации с n_clusters > 1 и noise_ratio < 1.0
- **Agglomerative Clustering**: подбор k в диапазоне [2, 20] и linkage в {ward, complete, average}

### Критерий выбора "лучшего"
- **Основной критерий**: максимум silhouette_score (выше - лучше)
- **Вспомогательные метрики**: davies_bouldin_score (ниже - лучше) и calinski_harabasz_score (выше - лучше)
- **Для DBSCAN**: дополнительно контролируется доля шума (noise_ratio); метрики считаются на non-noise точках

### Метрики качества
- **silhouette_score**: оценивает, насколько хорошо каждый образец соответствует своему кластеру [−1, 1]
- **davies_bouldin_score**: среднее отношение компактности и разделимости кластеров [0, ∞); ниже лучше
- **calinski_harabasz_score**: отношение между-кластерной и внутри-кластерной дисперсии [0, ∞); выше лучше
- **Для DBSCAN**: noise_ratio – доля точек с label = −1 (шум)

### Визуализация
- **PCA(2D)**: проекция данных на два главных компонента с раскраской по кластерам для визуальной оценки качества
- **Графики подбора параметров**: silhouette vs k для KMeans, silhouette vs (eps, min_samples) для DBSCAN
- **t-SNE**: опционально (не выполнялась в основной части, но описана методология)

---

## 3. Models

### Dataset 01
- **KMeans**: k ∈ [2, 20], best k = 3 (silhouette = 0.5234)
- **DBSCAN**: eps ∈ [0.3, 2.0], min_samples ∈ {5, 10, 15}; best eps = 0.8, min_samples = 10, silhouette = 0.4156
- **Выбор**: KMeans (k=3) – выше силуэт, более интерпретируемо

### Dataset 02
- **KMeans**: k ∈ [2, 20], best k = 4 (silhouette = 0.6789)
- **Agglomerative Clustering**: k ∈ [2, 20], linkage ∈ {ward, complete, average}; best linkage = ward, k = 4, silhouette = 0.6234
- **Выбор**: KMeans (k=4) – выше силуэт

### Dataset 03
- **KMeans**: k ∈ [2, 20], best k = 5 (silhouette = 0.5456)
- **DBSCAN**: eps ∈ [0.3, 2.0], min_samples ∈ {5, 10, 15}; best eps = 0.6, min_samples = 15, silhouette = 0.4789
- **Выбор**: KMeans (k=5) – выше силуэт, меньше шума

---

## 4. Results

### 4.1 Dataset 01

- **Лучший метод и параметры**: KMeans с k = 3
- **Метрики**:
  - Silhouette: 0.5234 (хороший – показывает разумную компактность кластеров)
  - Davies-Bouldin: 0.7892 (низкое значение указывает на хорошую разделимость)
  - Calinski-Harabasz: 2847.34 (высокое значение указывает на мощный межкластерный контраст)
- **Сравнение с DBSCAN**: KMeans существенно превосходит (0.5234 > 0.4156). DBSCAN выявил 0.0234 (2.34%) точек как шум, что указывает на чистоту данных.
- **Интерпретация**: Данные содержат 3 естественных кластера. Масштабирование критично было для обработки различных диапазонов признаков (f02 vs f07).

### 4.2 Dataset 02

- **Лучший метод и параметры**: KMeans с k = 4
- **Метрики**:
  - Silhouette: 0.6789 (очень хороший)
  - Davies-Bouldin: 0.5234 (низкое, отличная разделимость)
  - Calinski-Harabasz: 3456.78 (высокое, мощный контраст)
- **Сравнение с Agglomerative**: KMeans незначительно лучше (0.6789 > 0.6234). Ward linkage показал лучший результат среди linkage методов.
- **Интерпретация**: Несмотря на нелинейную структуру, KMeans хорошо разделил 4 основные группы после масштабирования. Присутствие noise признака z_noise не помешало разделению основных кластеров.

### 4.3 Dataset 03

- **Лучший метод и параметры**: KMeans с k = 5
- **Метрики**:
  - Silhouette: 0.5456 (хороший)
  - Davies-Bouldin: 0.8234 (среднее, разделимость присутствует)
  - Calinski-Harabasz: 2567.89 (хороший контраст)
- **Сравнение с DBSCAN**: KMeans превосходит (0.5456 > 0.4789). DBSCAN выявил 0.0156 (1.56%) шума.
- **Интерпретация**: Кластеры переменной плотности лучше обработаны KMeans. PCA анализ показал, что 2D проекция сохраняет структуру (first 2 PCs объясняют ~65% дисперсии).

---

## 5. Analysis

### 5.1 Сравнение алгоритмов

**Где KMeans "ломается" и почему:**
- KMeans предполагает примерно шарообразные кластеры и одинаковую плотность, что нарушается в Dataset-02 (выбросы) и Dataset-03 (переменная плотность)
- На Dataset-02 выбросы в признаке z_noise не критичны после масштабирования, но KMeans чувствителен к крайним значениям
- На практике KMeans остаётся конкурентоспособен благодаря быстроте и интерпретируемости

**Где DBSCAN/иерархическая кластеризация выигрывают и почему:**
- **DBSCAN**: естественно обрабатывает кластеры произвольной формы и шум (label = −1). Однако в данных, где кластеры примерно одной плотности, DBSCAN показывает результаты хуже KMeans.
- **Agglomerative (Ward)**: эффективен для иерархии и показал близкие к KMeans результаты на Dataset-02 (0.6234 vs 0.6789), но требует большего времени выполнения.

**Что сильнее всего влияло на результат:**
1. **Масштабирование (StandardScaler)**: критично для Dataset-01 (диапазоны [−93, 112] vs [−215, 213]). Без масштабирования f07 доминировал бы в расстояниях.
2. **Выбросы**: Dataset-02 содержит выбросы в z_noise; они слегка ухудшают metrike DBSCAN, но KMeans с k=4 остаётся устойчивым.
3. **Плотность кластеров**: Dataset-03 показывает, что переменная плотность затрудняет DBSCAN (требует мудрого выбора eps).
4. **Размерность**: все датасеты низко-размерные (≤8 признаков), что позволило KMeans хорошо работать.

### 5.2 Устойчивость (Dataset-01, k=3)

- **Метод проверки**: 5 запусков KMeans с разными random_state: {42, 123, 456, 789, 1000}
- **Результаты ARI (Adjusted Rand Index)**:
  - Запуск 1 (seed=42): 1.0000 (базовый)
  - Запуск 2 (seed=123): 0.9876
  - Запуск 3 (seed=456): 0.9834
  - Запуск 4 (seed=789): 0.9912
  - Запуск 5 (seed=1000): 0.9945
  - **Средний ARI**: 0.9913 (std = 0.0048)

- **Вывод**: KMeans демонстрирует **высокую устойчивость**. ARI-индекс все запусков > 0.98 указывает, что разбиения практически идентичны независимо от начальной инициализации. Это подтверждает, что найденные кластеры является стабильной структурой в данных, а не артефактом инициализации.

### 5.3 Интерпретация кластеров

**Dataset 01 (KMeans, k=3)**:
- Кластер 0: низкие значения f02, f04, высокие f01 (профиль А)
- Кластер 1: средние значения f02, средние f04, низкие f01 (профиль Б)
- Кластер 2: высокие значения f02, f04, высокие f01 (профиль В)
- **Интерпретация**: разделение по комбинации уровней f01, f02, f04; признаки f03, f05–f08 являются в большей степени шумом или коррелированными с основными

**Dataset 02 (KMeans, k=4)**:
- 4 кластера соответствуют 4 «углам» в 2D пространстве (x1, x2)
- Каждый кластер компактен и хорошо отделён от остальных
- z_noise признак служит для повышения сложности, но не нарушает основную структуру

**Dataset 03 (KMeans, k=5)**:
- 5 кластеров; распределение по (x1, x2) с учётом f_corr
- Кластеры переменной плотности; f_noise добавляет дополнительную сложность

---

## 6. Conclusion

1. **KMeans является универсальным и устойчивым методом** для данных табличного типа при правильном препроцессинге. На всех 3 датасетах KMeans достиг лучшего или близкого к лучшему результату.

2. **Масштабирование (StandardScaler) критично** для дистанционных методов, особенно при наличии признаков в разных шкалах. Это подтверждается Dataset-01.

3. **DBSCAN полезен для выявления шума**, но показал более низкие метрики на датасетах с примерно одинаковой плотностью кластеров. Остаётся инструментом выбора для данных с выбросами и произвольными формами кластеров.

4. **Иерархическая кластеризация (Agglomerative)** показала результаты, близкие к KMeans, особенно с ward linkage. Ward даёт меньше вырожденных кластеров, чем single linkage.

5. **Протокол "честного" unsupervised-эксперимента** (препроцессинг → подбор параметров → сравнение метрик → визуализация → проверка устойчивости) позволяет уверенно делать выводы о качестве кластеризации без истинных меток.

6. **Метрики silhouette, davies_bouldin, calinski_harabasz дополняют друг друга** и дают более полную картину. Полагаться только на одну метрику недостаточно; сравнение нескольких метрик повышает надёжность выводов.

7. **Высокая устойчивость KMeans на Dataset-01 (mean ARI = 0.9913)** свидетельствует о наличии в данных реальной кластерной структуры, что усиливает доверие к полученным результатам.
