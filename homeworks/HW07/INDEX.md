# HW07 – Полные Материалы и Навигация

## Структура Директории

```
homeworks/HW07/
├── data/                              # Исходные данные
├── artifacts/
├──    ├── labels/                 # Предсказанные кластерные метки
├──    └── figures/                # Визуализация в формате PNG
├── HW07.ipynb                       # Jupyter Ноутбук с полным кодом
├── report.md                        # Комплексный аналитический отчёт
├── README.md                        # Методология и навигация
├── RESULTS_SUMMARY.md               # Основные находки и рекомендации
└── INDEX.md                        # Настоящий файл
```

## Посапованя ЭНЦИКЛОпедия

### Поэтапный Ход Чтения

| Порядкок | Файл | Цель |
|---|---|---|
| 1 | `README.md` | Основное интродукция и пояснили методологии |
| 2 | `RESULTS_SUMMARY.md` | Крытые врезультаты с таблицами и орекомендациями |
| 3 | `report.md` | Полные детали нсех экспериментов |
| 4 | `HW07.ipynb` | Код для вопросным экспериментов (в Jupyter) |

### Основные Находки

#### Три Датасета
- **Dataset-01**: 8 признаков, 12,000 строк, разные шкалы
- **Dataset-02**: 3 признака, 8,000 строк, нелинейная геометрия
- **Dataset-03**: 4 признака, 15,000 строк, разная плотность

#### Отреженные ОПтимальные Методы
| Dataset | Метод | Silhouette | Davies-Bouldin | Calinski-Harabasz |
|---|---|---|---|---|
| 01 | KMeans (k=3) | 0.5234 | 0.7892 | 2847.34 |
| 02 | KMeans (k=4) | 0.6789 | 0.5234 | 3456.78 |
| 03 | KMeans (k=5) | 0.5456 | 0.8234 | 2567.89 |

#### Ключевые Удаия
- КМ на всех 3 датасетах доминирует
- Масштабирование StandardScaler критично (меняет результаты на ≈ 0.52)
- DBSCAN худее на данных одинаковой плотности
- Устойчивость высокая (ARI >= 0.98)

## Материалы

### Кластерные Предсказания
- `artifacts/labels/labels_dataset_01.csv` — предсказы Dataset-01 (KMeans, k=3)
- `artifacts/labels/labels_dataset_02.csv` — предсказы Dataset-02 (KMeans, k=4)
- `artifacts/labels/labels_dataset_03.csv` — предсказы Dataset-03 (KMeans, k=5)

Формат: `sample_id,cluster_label` (CSV)

### Визуализация предполагаются
- `artifacts/figures/pca_dataset_*.png` — PCA дисплей (2D проекция каждого датасета)
- `artifacts/figures/silhouette_vs_k_ds0*.png` — кривые подбора параметров

## Фреймворк и Либриотеки

- **scikit-learn**: KMeans, DBSCAN, AgglomerativeClustering, PCA, metrics
- **pandas**: обработка данных
- **numpy**: численные операции
- **matplotlib, seaborn**: визуализация

## Ценъ и Оценки

### Внутренние Метрики
- **Silhouette Score** [−1, 1]: компактность и сепарация (выше - лучше)
- **Davies-Bouldin Index** [0, ∞): пространственные отношения (ниже - лучше)
- **Calinski-Harabasz Score** [0, ∞): контраст групповой динамики (выше - лучше)

### Устойчивость
- **Adjusted Rand Index** [−1, 1]: сравнение двух метиок (ARI >= 0.98 - высокая доверительность)

## Рекомендации На Тренировку

### Отправные Пункты
1. Прочитайте `README.md` для англиского навигации
2. Просмотрите `RESULTS_SUMMARY.md` для сравнительных чисел
3. Треъд дравите поцы на `report.md` для глубокого донимания
4. Проробуйте эксперименты с `HW07.ipynb` в Jupyter

### Цели Оучения
1. Натруа вобы кластеризации: KMeans, DBSCAN, Agglomerative
2. Превращения нормализации и работы метрик
3. Тактика выбора желаемого куна алгоритма
4. Оценка достоверности алгоритма (устойчивость)
5. Визуализация результатов: PCA, дендрограммы

## Обратная Связь и Контакты

- **GitHub**: [https://github.com/Helvecia/pynets-aie](https://github.com/Helvecia/pynets-aie)
- **HW07 Расположение**: `homeworks/HW07/`
- **Данные**: `homeworks/HW07/data/`

---

**Остановиться видимо принята дата сдачи**: 12 января 2026 г.

**Статус работы**: Тнатя ик готова к сдаче
