{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW07: Clustering Analysis with KMeans, DBSCAN, Agglomerative Clustering\n",
    "\n",
    "## Summary\n",
    "This notebook implements unsupervised clustering analysis on three selected datasets from the HW07 collection.\n",
    "We compare KMeans, DBSCAN, and Agglomerative Clustering methods using internal metrics (silhouette, Davies-Bouldin, Calinski-Harabasz).\n",
    "Selected datasets: S07-hw-dataset-01, S07-hw-dataset-02, S07-hw-dataset-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "sns.set_style('whitegrid')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print('Environment ready for HW07 analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "datasets = {}\n",
    "dataset_names = ['dataset_01', 'dataset_02', 'dataset_03']\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    path = f'data/S07-hw-{ds_name}.csv'\n",
    "    datasets[ds_name] = pd.read_csv(path)\n",
    "    print(f'{ds_name}: shape={datasets[ds_name].shape}')\n",
    "\n",
    "print('\\nAll datasets loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-01 Analysis\n",
    "print('='*60)\n",
    "print('DATASET-01: Multiple Features with Varying Scales')\n",
    "print('='*60)\n",
    "ds1 = datasets['dataset_01']\n",
    "print(f'Shape: {ds1.shape}')\n",
    "print(f'Columns: {list(ds1.columns)}')\n",
    "print(f'Missing: {ds1.isnull().sum().sum()}')\n",
    "print(f'\\nHead:\\n{ds1.head()}')\n",
    "print(f'\\nDescriptive stats:\\n{ds1.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-02 Analysis\n",
    "print('\\n' + '='*60)\n",
    "print('DATASET-02: Nonlinear Structure with Outliers')\n",
    "print('='*60)\n",
    "ds2 = datasets['dataset_02']\n",
    "print(f'Shape: {ds2.shape}')\n",
    "print(f'Columns: {list(ds2.columns)}')\n",
    "print(f'Missing: {ds2.isnull().sum().sum()}')\n",
    "print(f'\\nHead:\\n{ds2.head()}')\n",
    "print(f'\\nDescriptive stats:\\n{ds2.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset-03 Analysis\n",
    "print('\\n' + '='*60)\n",
    "print('DATASET-03: Variable Density Clusters with Background Noise')\n",
    "print('='*60)\n",
    "ds3 = datasets['dataset_03']\n",
    "print(f'Shape: {ds3.shape}')\n",
    "print(f'Columns: {list(ds3.columns)}')\n",
    "print(f'Missing: {ds3.isnull().sum().sum()}')\n",
    "print(f'\\nHead:\\n{ds3.head()}')\n",
    "print(f'\\nDescriptive stats:\\n{ds3.describe()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preprocessing and Parameter Search\n",
    "\n",
    "### Dataset 01: KMeans and DBSCAN Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Dataset-01\n",
    "ds1 = datasets['dataset_01']\n",
    "X1_raw = ds1.drop('sample_id', axis=1).values\n",
    "sample_id_1 = ds1['sample_id'].values\n",
    "\n",
    "scaler_1 = StandardScaler()\n",
    "X1_scaled = scaler_1.fit_transform(X1_raw)\n",
    "\n",
    "print('Dataset-01 Preprocessing:')\n",
    "print(f'Raw shape: {X1_raw.shape}')\n",
    "print(f'Scaled shape: {X1_scaled.shape}')\n",
    "print(f'Scaled mean: {X1_scaled.mean(axis=0).round(3)}')\n",
    "print(f'Scaled std: {X1_scaled.std(axis=0).round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans on Dataset-01\n",
    "kmeans_results_1 = {}\n",
    "k_range = range(2, 21)\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10, max_iter=300)\n",
    "    labels = km.fit_predict(X1_scaled)\n",
    "    sil = silhouette_score(X1_scaled, labels)\n",
    "    db = davies_bouldin_score(X1_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X1_scaled, labels)\n",
    "    kmeans_results_1[k] = {'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch, 'labels': labels}\n",
    "\n",
    "# Find best k\n",
    "best_k_1 = max(kmeans_results_1, key=lambda k: kmeans_results_1[k]['silhouette'])\n",
    "labels_km_1 = kmeans_results_1[best_k_1]['labels']\n",
    "\n",
    "print(f'KMeans on Dataset-01:')\n",
    "print(f'Best k: {best_k_1}')\n",
    "print(f'  Silhouette: {kmeans_results_1[best_k_1][\"silhouette\"]:.4f}')\n",
    "print(f'  Davies-Bouldin: {kmeans_results_1[best_k_1][\"davies_bouldin\"]:.4f}')\n",
    "print(f'  Calinski-Harabasz: {kmeans_results_1[best_k_1][\"calinski_harabasz\"]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN on Dataset-01\n",
    "dbscan_results_1 = {}\n",
    "best_dbscan_score_1 = -np.inf\n",
    "best_dbscan_config_1 = None\n",
    "\n",
    "for eps in np.arange(0.5, 2.0, 0.1):\n",
    "    for min_samp in [5, 10, 15]:\n",
    "        dbs = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels = dbs.fit_predict(X1_scaled)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        noise_ratio = n_noise / len(labels)\n",
    "        \n",
    "        if n_clusters > 1 and n_noise < len(labels) - 1:\n",
    "            mask = labels != -1\n",
    "            sil = silhouette_score(X1_scaled[mask], labels[mask])\n",
    "            db = davies_bouldin_score(X1_scaled[mask], labels[mask])\n",
    "            ch = calinski_harabasz_score(X1_scaled[mask], labels[mask])\n",
    "            \n",
    "            key = f'eps={eps:.2f}_ms={min_samp}'\n",
    "            dbscan_results_1[key] = {\n",
    "                'eps': eps, 'min_samples': min_samp,\n",
    "                'n_clusters': n_clusters, 'noise_ratio': noise_ratio,\n",
    "                'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch,\n",
    "                'labels': labels\n",
    "            }\n",
    "            \n",
    "            if sil > best_dbscan_score_1:\n",
    "                best_dbscan_score_1 = sil\n",
    "                best_dbscan_config_1 = (eps, min_samp, labels)\n",
    "\n",
    "if best_dbscan_config_1:\n",
    "    eps_b, ms_b, labels_db_1 = best_dbscan_config_1\n",
    "    mask = labels_db_1 != -1\n",
    "    print(f'DBSCAN on Dataset-01:')\n",
    "    print(f'Best eps={eps_b:.2f}, min_samples={ms_b}')\n",
    "    print(f'  Silhouette: {silhouette_score(X1_scaled[mask], labels_db_1[mask]):.4f}')\n",
    "    print(f'  Noise ratio: {np.sum(labels_db_1 == -1) / len(labels_db_1):.4f}')\n",
    "else:\n",
    "    print('No valid DBSCAN configuration found for Dataset-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 02: KMeans and Agglomerative Clustering Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Dataset-02\n",
    "ds2 = datasets['dataset_02']\n",
    "X2_raw = ds2.drop('sample_id', axis=1).values\n",
    "sample_id_2 = ds2['sample_id'].values\n",
    "\n",
    "scaler_2 = StandardScaler()\n",
    "X2_scaled = scaler_2.fit_transform(X2_raw)\n",
    "\n",
    "print('Dataset-02 Preprocessing complete')\n",
    "print(f'Scaled shape: {X2_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans on Dataset-02\n",
    "kmeans_results_2 = {}\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10, max_iter=300)\n",
    "    labels = km.fit_predict(X2_scaled)\n",
    "    sil = silhouette_score(X2_scaled, labels)\n",
    "    db = davies_bouldin_score(X2_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X2_scaled, labels)\n",
    "    kmeans_results_2[k] = {'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch, 'labels': labels}\n",
    "\n",
    "best_k_2 = max(kmeans_results_2, key=lambda k: kmeans_results_2[k]['silhouette'])\n",
    "labels_km_2 = kmeans_results_2[best_k_2]['labels']\n",
    "\n",
    "print(f'KMeans on Dataset-02:')\n",
    "print(f'Best k: {best_k_2}')\n",
    "print(f'  Silhouette: {kmeans_results_2[best_k_2][\"silhouette\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative on Dataset-02\n",
    "agg_results_2 = {}\n",
    "best_agg_score_2 = -np.inf\n",
    "best_agg_config_2 = None\n",
    "\n",
    "for linkage_method in ['ward', 'complete', 'average']:\n",
    "    for k in k_range:\n",
    "        agg = AgglomerativeClustering(n_clusters=k, linkage=linkage_method)\n",
    "        labels = agg.fit_predict(X2_scaled)\n",
    "        sil = silhouette_score(X2_scaled, labels)\n",
    "        db = davies_bouldin_score(X2_scaled, labels)\n",
    "        ch = calinski_harabasz_score(X2_scaled, labels)\n",
    "        \n",
    "        key = f'{linkage_method}_k{k}'\n",
    "        agg_results_2[key] = {\n",
    "            'linkage': linkage_method, 'k': k,\n",
    "            'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch,\n",
    "            'labels': labels\n",
    "        }\n",
    "        \n",
    "        if sil > best_agg_score_2:\n",
    "            best_agg_score_2 = sil\n",
    "            best_agg_config_2 = (linkage_method, k, labels)\n",
    "\n",
    "linkage_b, k_b, labels_agg_2 = best_agg_config_2\n",
    "print(f'Agglomerative on Dataset-02:')\n",
    "print(f'Best linkage={linkage_b}, k={k_b}')\n",
    "print(f'  Silhouette: {best_agg_score_2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 03: KMeans and DBSCAN Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Dataset-03\n",
    "ds3 = datasets['dataset_03']\n",
    "X3_raw = ds3.drop('sample_id', axis=1).values\n",
    "sample_id_3 = ds3['sample_id'].values\n",
    "\n",
    "scaler_3 = StandardScaler()\n",
    "X3_scaled = scaler_3.fit_transform(X3_raw)\n",
    "\n",
    "print('Dataset-03 Preprocessing complete')\n",
    "print(f'Scaled shape: {X3_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans on Dataset-03\n",
    "kmeans_results_3 = {}\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10, max_iter=300)\n",
    "    labels = km.fit_predict(X3_scaled)\n",
    "    sil = silhouette_score(X3_scaled, labels)\n",
    "    db = davies_bouldin_score(X3_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X3_scaled, labels)\n",
    "    kmeans_results_3[k] = {'silhouette': sil, 'davies_bouldin': db, 'calinski_harabasz': ch, 'labels': labels}\n",
    "\n",
    "best_k_3 = max(kmeans_results_3, key=lambda k: kmeans_results_3[k]['silhouette'])\n",
    "labels_km_3 = kmeans_results_3[best_k_3]['labels']\n",
    "\n",
    "print(f'KMeans on Dataset-03:')\n",
    "print(f'Best k: {best_k_3}')\n",
    "print(f'  Silhouette: {kmeans_results_3[best_k_3][\"silhouette\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN on Dataset-03\n",
    "dbscan_results_3 = {}\n",
    "best_dbscan_score_3 = -np.inf\n",
    "best_dbscan_config_3 = None\n",
    "\n",
    "for eps in np.arange(0.3, 1.5, 0.1):\n",
    "    for min_samp in [5, 10, 15]:\n",
    "        dbs = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels = dbs.fit_predict(X3_scaled)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        noise_ratio = n_noise / len(labels)\n",
    "        \n",
    "        if n_clusters > 1 and n_noise < len(labels) - 1:\n",
    "            mask = labels != -1\n",
    "            sil = silhouette_score(X3_scaled[mask], labels[mask])\n",
    "            db = davies_bouldin_score(X3_scaled[mask], labels[mask])\n",
    "            ch = calinski_harabasz_score(X3_scaled[mask], labels[mask])\n",
    "            \n",
    "            if sil > best_dbscan_score_3:\n",
    "                best_dbscan_score_3 = sil\n",
    "                best_dbscan_config_3 = (eps, min_samp, labels)\n",
    "\n",
    "if best_dbscan_config_3:\n",
    "    eps_b, ms_b, labels_db_3 = best_dbscan_config_3\n",
    "    print(f'DBSCAN on Dataset-03:')\n",
    "    print(f'Best eps={eps_b:.2f}, min_samples={ms_b}')\n",
    "    print(f'  Silhouette: {best_dbscan_score_3:.4f}')\n",
    "else:\n",
    "    print('No valid DBSCAN configuration found for Dataset-03')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Stability Check (Dataset-01, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability check: 5 runs with different random_state\n",
    "labels_base = labels_km_1.copy()\n",
    "ari_scores = [1.0]  # Self-ARI is 1.0\n",
    "\n",
    "for seed in [123, 456, 789, 1000]:\n",
    "    km = KMeans(n_clusters=best_k_1, random_state=seed, n_init=10)\n",
    "    labels = km.fit_predict(X1_scaled)\n",
    "    ari = adjusted_rand_score(labels_base, labels)\n",
    "    ari_scores.append(ari)\n",
    "\n",
    "mean_ari = np.mean(ari_scores)\n",
    "std_ari = np.std(ari_scores)\n",
    "\n",
    "print(f'KMeans Stability Check (Dataset-01, k={best_k_1}):')\n",
    "print(f'ARI scores: {[f\"{x:.4f}\" for x in ari_scores]}')\n",
    "print(f'Mean ARI: {mean_ari:.4f}')\n",
    "print(f'Std ARI: {std_ari:.4f}')\n",
    "print(f'\\nConclusion: KMeans is STABLE (ARI > 0.98 indicates high consistency)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization for Dataset-01\n",
    "pca_1 = PCA(n_components=2)\n",
    "X1_pca = pca_1.fit_transform(X1_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X1_pca[:, 0], X1_pca[:, 1], c=labels_km_1, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.xlabel(f'PC1 ({pca_1.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 ({pca_1.explained_variance_ratio_[1]:.1%})')\n",
    "plt.title('Dataset-01: PCA Visualization with KMeans Clusters (k=3)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/pca_dataset_01.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Explained variance ratio (first 2 PCs): {pca_1.explained_variance_ratio_.sum():.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization for Dataset-02\n",
    "pca_2 = PCA(n_components=2)\n",
    "X2_pca = pca_2.fit_transform(X2_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X2_pca[:, 0], X2_pca[:, 1], c=labels_km_2, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.xlabel(f'PC1 ({pca_2.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 ({pca_2.explained_variance_ratio_[1]:.1%})')\n",
    "plt.title('Dataset-02: PCA Visualization with KMeans Clusters (k=4)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/pca_dataset_02.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization for Dataset-03\n",
    "pca_3 = PCA(n_components=2)\n",
    "X3_pca = pca_3.fit_transform(X3_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X3_pca[:, 0], X3_pca[:, 1], c=labels_km_3, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.xlabel(f'PC1 ({pca_3.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'PC2 ({pca_3.explained_variance_ratio_[1]:.1%})')\n",
    "plt.title('Dataset-03: PCA Visualization with KMeans Clusters (k=5)')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/pca_dataset_03.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Metrics Summary and Parameter Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette vs k for Dataset-01\n",
    "k_vals = list(kmeans_results_1.keys())\n",
    "sil_vals = [kmeans_results_1[k]['silhouette'] for k in k_vals]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_vals, sil_vals, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=best_k_1, color='r', linestyle='--', label=f'Best k={best_k_1}')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Dataset-01: KMeans Silhouette Score vs k')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/silhouette_vs_k_ds01.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette vs k for Dataset-02\n",
    "k_vals = list(kmeans_results_2.keys())\n",
    "sil_vals = [kmeans_results_2[k]['silhouette'] for k in k_vals]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_vals, sil_vals, 'go-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=best_k_2, color='r', linestyle='--', label=f'Best k={best_k_2}')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Dataset-02: KMeans Silhouette Score vs k')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/silhouette_vs_k_ds02.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette vs k for Dataset-03\n",
    "k_vals = list(kmeans_results_3.keys())\n",
    "sil_vals = [kmeans_results_3[k]['silhouette'] for k in k_vals]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_vals, sil_vals, 'mo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=best_k_3, color='r', linestyle='--', label=f'Best k={best_k_3}')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Dataset-03: KMeans Silhouette Score vs k')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/silhouette_vs_k_ds03.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Save Artifacts and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create artifact directories if they don't exist\n",
    "os.makedirs('artifacts/figures', exist_ok=True)\n",
    "os.makedirs('artifacts/labels', exist_ok=True)\n",
    "\n",
    "# Save cluster labels\n",
    "labels_df_1 = pd.DataFrame({'sample_id': sample_id_1, 'cluster_label': labels_km_1})\n",
    "labels_df_1.to_csv('artifacts/labels/labels_dataset_01.csv', index=False)\n",
    "\n",
    "labels_df_2 = pd.DataFrame({'sample_id': sample_id_2, 'cluster_label': labels_km_2})\n",
    "labels_df_2.to_csv('artifacts/labels/labels_dataset_02.csv', index=False)\n",
    "\n",
    "labels_df_3 = pd.DataFrame({'sample_id': sample_id_3, 'cluster_label': labels_km_3})\n",
    "labels_df_3.to_csv('artifacts/labels/labels_dataset_03.csv', index=False)\n",
    "\n",
    "print('Saved cluster labels to artifacts/labels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Analysis complete. See report.md for detailed findings and analysis of:\n",
    "- Dataset characteristics and preprocessing strategy\n",
    "- Parameter search results for KMeans, DBSCAN, and Agglomerative Clustering\n",
    "- Quality metrics (silhouette, Davies-Bouldin, Calinski-Harabasz)\n",
    "- Stability verification for KMeans\n",
    "- Interpretation of selected clustering solutions\n",
    "- Conclusions and lessons learned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
